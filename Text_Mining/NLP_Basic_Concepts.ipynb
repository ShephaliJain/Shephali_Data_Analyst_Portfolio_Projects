{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShephaliJain/Shephali_Data_Analyst_Portfolio_Projects/blob/main/Text_Mining/NLP_Basic_Concepts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTBLDxDCggWL"
      },
      "source": [
        "# **NLP Basics: What is Natural Language Processing & the Natural Language Toolkit?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4tkkgA1ggWQ"
      },
      "source": [
        "### How to install NLTK on your local machine\n",
        "\n",
        "Both sets of instructions below assume you already have Python installed. These instructions are taken directly from [http://www.nltk.org/install.html](http://www.nltk.org/install.html).\n",
        "\n",
        "**Mac/Unix**\n",
        "\n",
        "From the terminal:\n",
        "1. Install NLTK: run `pip install -U nltk`\n",
        "2. Test installation: run `python` then type `import nltk`\n",
        "\n",
        "**Windows**\n",
        "\n",
        "1. Install NLTK: [http://pypi.python.org/pypi/nltk](http://pypi.python.org/pypi/nltk)\n",
        "2. Test installation: `Start>Python35`, then type `import nltk`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9vrwSUkggWS"
      },
      "source": [
        "### **Download NLTK data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLsg-5jLggWU"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "#nltk.download()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D2Z9jcJggWX",
        "outputId": "536b1543-171d-4725-b5f8-f58365c01c5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AbstractLazySequence',\n",
              " 'AffixTagger',\n",
              " 'AlignedSent',\n",
              " 'Alignment',\n",
              " 'AnnotationTask',\n",
              " 'ApplicationExpression',\n",
              " 'Assignment',\n",
              " 'BigramAssocMeasures',\n",
              " 'BigramCollocationFinder',\n",
              " 'BigramTagger',\n",
              " 'BinaryMaxentFeatureEncoding',\n",
              " 'BlanklineTokenizer',\n",
              " 'BllipParser',\n",
              " 'BottomUpChartParser',\n",
              " 'BottomUpLeftCornerChartParser',\n",
              " 'BottomUpProbabilisticChartParser',\n",
              " 'Boxer',\n",
              " 'BrillTagger',\n",
              " 'BrillTaggerTrainer',\n",
              " 'CFG',\n",
              " 'CRFTagger',\n",
              " 'CfgReadingCommand',\n",
              " 'ChartParser',\n",
              " 'ChunkParserI',\n",
              " 'ChunkScore',\n",
              " 'ClassifierBasedPOSTagger',\n",
              " 'ClassifierBasedTagger',\n",
              " 'ClassifierI',\n",
              " 'ConcordanceIndex',\n",
              " 'ConditionalExponentialClassifier',\n",
              " 'ConditionalFreqDist',\n",
              " 'ConditionalProbDist',\n",
              " 'ConditionalProbDistI',\n",
              " 'ConfusionMatrix',\n",
              " 'ContextIndex',\n",
              " 'ContextTagger',\n",
              " 'ContingencyMeasures',\n",
              " 'CoreNLPDependencyParser',\n",
              " 'CoreNLPParser',\n",
              " 'Counter',\n",
              " 'CrossValidationProbDist',\n",
              " 'DRS',\n",
              " 'DecisionTreeClassifier',\n",
              " 'DefaultTagger',\n",
              " 'DependencyEvaluator',\n",
              " 'DependencyGrammar',\n",
              " 'DependencyGraph',\n",
              " 'DependencyProduction',\n",
              " 'DictionaryConditionalProbDist',\n",
              " 'DictionaryProbDist',\n",
              " 'DiscourseTester',\n",
              " 'DrtExpression',\n",
              " 'DrtGlueReadingCommand',\n",
              " 'ELEProbDist',\n",
              " 'EarleyChartParser',\n",
              " 'Expression',\n",
              " 'FStructure',\n",
              " 'FeatDict',\n",
              " 'FeatList',\n",
              " 'FeatStruct',\n",
              " 'FeatStructReader',\n",
              " 'Feature',\n",
              " 'FeatureBottomUpChartParser',\n",
              " 'FeatureBottomUpLeftCornerChartParser',\n",
              " 'FeatureChartParser',\n",
              " 'FeatureEarleyChartParser',\n",
              " 'FeatureIncrementalBottomUpChartParser',\n",
              " 'FeatureIncrementalBottomUpLeftCornerChartParser',\n",
              " 'FeatureIncrementalChartParser',\n",
              " 'FeatureIncrementalTopDownChartParser',\n",
              " 'FeatureTopDownChartParser',\n",
              " 'FreqDist',\n",
              " 'HTTPPasswordMgrWithDefaultRealm',\n",
              " 'HeldoutProbDist',\n",
              " 'HiddenMarkovModelTagger',\n",
              " 'HiddenMarkovModelTrainer',\n",
              " 'HunposTagger',\n",
              " 'IBMModel',\n",
              " 'IBMModel1',\n",
              " 'IBMModel2',\n",
              " 'IBMModel3',\n",
              " 'IBMModel4',\n",
              " 'IBMModel5',\n",
              " 'ISRIStemmer',\n",
              " 'ImmutableMultiParentedTree',\n",
              " 'ImmutableParentedTree',\n",
              " 'ImmutableProbabilisticMixIn',\n",
              " 'ImmutableProbabilisticTree',\n",
              " 'ImmutableTree',\n",
              " 'IncrementalBottomUpChartParser',\n",
              " 'IncrementalBottomUpLeftCornerChartParser',\n",
              " 'IncrementalChartParser',\n",
              " 'IncrementalLeftCornerChartParser',\n",
              " 'IncrementalTopDownChartParser',\n",
              " 'Index',\n",
              " 'InsideChartParser',\n",
              " 'JSONTaggedDecoder',\n",
              " 'JSONTaggedEncoder',\n",
              " 'KneserNeyProbDist',\n",
              " 'LancasterStemmer',\n",
              " 'LaplaceProbDist',\n",
              " 'LazyConcatenation',\n",
              " 'LazyEnumerate',\n",
              " 'LazyIteratorList',\n",
              " 'LazyMap',\n",
              " 'LazySubsequence',\n",
              " 'LazyZip',\n",
              " 'LeftCornerChartParser',\n",
              " 'LidstoneProbDist',\n",
              " 'LineTokenizer',\n",
              " 'LogicalExpressionException',\n",
              " 'LongestChartParser',\n",
              " 'MLEProbDist',\n",
              " 'MWETokenizer',\n",
              " 'Mace',\n",
              " 'MaceCommand',\n",
              " 'MaltParser',\n",
              " 'MaxentClassifier',\n",
              " 'Model',\n",
              " 'MultiClassifierI',\n",
              " 'MultiParentedTree',\n",
              " 'MutableProbDist',\n",
              " 'NaiveBayesClassifier',\n",
              " 'NaiveBayesDependencyScorer',\n",
              " 'NgramAssocMeasures',\n",
              " 'NgramTagger',\n",
              " 'NonprojectiveDependencyParser',\n",
              " 'Nonterminal',\n",
              " 'OrderedDict',\n",
              " 'PCFG',\n",
              " 'Paice',\n",
              " 'ParallelProverBuilder',\n",
              " 'ParallelProverBuilderCommand',\n",
              " 'ParentedTree',\n",
              " 'ParserI',\n",
              " 'PerceptronTagger',\n",
              " 'PhraseTable',\n",
              " 'PorterStemmer',\n",
              " 'PositiveNaiveBayesClassifier',\n",
              " 'ProbDistI',\n",
              " 'ProbabilisticDependencyGrammar',\n",
              " 'ProbabilisticMixIn',\n",
              " 'ProbabilisticNonprojectiveParser',\n",
              " 'ProbabilisticProduction',\n",
              " 'ProbabilisticProjectiveDependencyParser',\n",
              " 'ProbabilisticTree',\n",
              " 'Production',\n",
              " 'ProjectiveDependencyParser',\n",
              " 'Prover9',\n",
              " 'Prover9Command',\n",
              " 'ProxyBasicAuthHandler',\n",
              " 'ProxyDigestAuthHandler',\n",
              " 'ProxyHandler',\n",
              " 'PunktSentenceTokenizer',\n",
              " 'QuadgramCollocationFinder',\n",
              " 'RSLPStemmer',\n",
              " 'RTEFeatureExtractor',\n",
              " 'RUS_PICKLE',\n",
              " 'RandomChartParser',\n",
              " 'RangeFeature',\n",
              " 'ReadingCommand',\n",
              " 'RecursiveDescentParser',\n",
              " 'RegexpChunkParser',\n",
              " 'RegexpParser',\n",
              " 'RegexpStemmer',\n",
              " 'RegexpTagger',\n",
              " 'RegexpTokenizer',\n",
              " 'ReppTokenizer',\n",
              " 'ResolutionProver',\n",
              " 'ResolutionProverCommand',\n",
              " 'SExprTokenizer',\n",
              " 'SLASH',\n",
              " 'Senna',\n",
              " 'SennaChunkTagger',\n",
              " 'SennaNERTagger',\n",
              " 'SennaTagger',\n",
              " 'SequentialBackoffTagger',\n",
              " 'ShiftReduceParser',\n",
              " 'SimpleGoodTuringProbDist',\n",
              " 'SklearnClassifier',\n",
              " 'SlashFeature',\n",
              " 'SnowballStemmer',\n",
              " 'SpaceTokenizer',\n",
              " 'StackDecoder',\n",
              " 'StanfordNERTagger',\n",
              " 'StanfordPOSTagger',\n",
              " 'StanfordSegmenter',\n",
              " 'StanfordTagger',\n",
              " 'StemmerI',\n",
              " 'SteppingChartParser',\n",
              " 'SteppingRecursiveDescentParser',\n",
              " 'SteppingShiftReduceParser',\n",
              " 'TYPE',\n",
              " 'TabTokenizer',\n",
              " 'TableauProver',\n",
              " 'TableauProverCommand',\n",
              " 'TaggerI',\n",
              " 'TestGrammar',\n",
              " 'Text',\n",
              " 'TextCat',\n",
              " 'TextCollection',\n",
              " 'TextTilingTokenizer',\n",
              " 'TnT',\n",
              " 'TokenSearcher',\n",
              " 'ToktokTokenizer',\n",
              " 'TopDownChartParser',\n",
              " 'TransitionParser',\n",
              " 'Tree',\n",
              " 'TreebankWordTokenizer',\n",
              " 'Trie',\n",
              " 'TrigramAssocMeasures',\n",
              " 'TrigramCollocationFinder',\n",
              " 'TrigramTagger',\n",
              " 'TweetTokenizer',\n",
              " 'TypedMaxentFeatureEncoding',\n",
              " 'Undefined',\n",
              " 'UniformProbDist',\n",
              " 'UnigramTagger',\n",
              " 'UnsortedChartParser',\n",
              " 'Valuation',\n",
              " 'Variable',\n",
              " 'ViterbiParser',\n",
              " 'WekaClassifier',\n",
              " 'WhitespaceTokenizer',\n",
              " 'WittenBellProbDist',\n",
              " 'WordNetLemmatizer',\n",
              " 'WordPunctTokenizer',\n",
              " '__author__',\n",
              " '__author_email__',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__classifiers__',\n",
              " '__copyright__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__keywords__',\n",
              " '__license__',\n",
              " '__loader__',\n",
              " '__longdescr__',\n",
              " '__maintainer__',\n",
              " '__maintainer_email__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '__url__',\n",
              " '__version__',\n",
              " 'absolute_import',\n",
              " 'accuracy',\n",
              " 'add_logs',\n",
              " 'agreement',\n",
              " 'align',\n",
              " 'alignment_error_rate',\n",
              " 'aline',\n",
              " 'api',\n",
              " 'app',\n",
              " 'apply_features',\n",
              " 'approxrand',\n",
              " 'arity',\n",
              " 'association',\n",
              " 'bigrams',\n",
              " 'binary_distance',\n",
              " 'binary_search_file',\n",
              " 'binding_ops',\n",
              " 'bisect',\n",
              " 'blankline_tokenize',\n",
              " 'bleu',\n",
              " 'bleu_score',\n",
              " 'bllip',\n",
              " 'boolean_ops',\n",
              " 'boxer',\n",
              " 'bracket_parse',\n",
              " 'breadth_first',\n",
              " 'brill',\n",
              " 'brill_trainer',\n",
              " 'build_opener',\n",
              " 'call_megam',\n",
              " 'casual',\n",
              " 'casual_tokenize',\n",
              " 'ccg',\n",
              " 'chain',\n",
              " 'chart',\n",
              " 'chat',\n",
              " 'choose',\n",
              " 'chunk',\n",
              " 'class_types',\n",
              " 'classify',\n",
              " 'clause',\n",
              " 'clean_html',\n",
              " 'clean_url',\n",
              " 'cluster',\n",
              " 'collections',\n",
              " 'collocations',\n",
              " 'combinations',\n",
              " 'compat',\n",
              " 'config_java',\n",
              " 'config_megam',\n",
              " 'config_weka',\n",
              " 'conflicts',\n",
              " 'confusionmatrix',\n",
              " 'conllstr2tree',\n",
              " 'conlltags2tree',\n",
              " 'corenlp',\n",
              " 'corpus',\n",
              " 'crf',\n",
              " 'custom_distance',\n",
              " 'data',\n",
              " 'decisiontree',\n",
              " 'decorator',\n",
              " 'decorators',\n",
              " 'defaultdict',\n",
              " 'demo',\n",
              " 'dependencygraph',\n",
              " 'deque',\n",
              " 'discourse',\n",
              " 'distance',\n",
              " 'download',\n",
              " 'download_gui',\n",
              " 'download_shell',\n",
              " 'downloader',\n",
              " 'draw',\n",
              " 'drt',\n",
              " 'earleychart',\n",
              " 'edit_distance',\n",
              " 'elementtree_indent',\n",
              " 'entropy',\n",
              " 'equality_preds',\n",
              " 'evaluate',\n",
              " 'evaluate_sents',\n",
              " 'everygrams',\n",
              " 'extract_rels',\n",
              " 'extract_test_sentences',\n",
              " 'f_measure',\n",
              " 'featstruct',\n",
              " 'featurechart',\n",
              " 'filestring',\n",
              " 'find',\n",
              " 'flatten',\n",
              " 'fractional_presence',\n",
              " 'getproxies',\n",
              " 'ghd',\n",
              " 'glue',\n",
              " 'grammar',\n",
              " 'guess_encoding',\n",
              " 'help',\n",
              " 'hmm',\n",
              " 'hunpos',\n",
              " 'ibm1',\n",
              " 'ibm2',\n",
              " 'ibm3',\n",
              " 'ibm4',\n",
              " 'ibm5',\n",
              " 'ibm_model',\n",
              " 'ieerstr2tree',\n",
              " 'improved_close_quote_regex',\n",
              " 'improved_open_quote_regex',\n",
              " 'improved_punct_regex',\n",
              " 'in_idle',\n",
              " 'induce_pcfg',\n",
              " 'inference',\n",
              " 'infile',\n",
              " 'inspect',\n",
              " 'install_opener',\n",
              " 'internals',\n",
              " 'interpret_sents',\n",
              " 'interval_distance',\n",
              " 'invert_dict',\n",
              " 'invert_graph',\n",
              " 'is_rel',\n",
              " 'islice',\n",
              " 'isri',\n",
              " 'jaccard_distance',\n",
              " 'json_tags',\n",
              " 'jsontags',\n",
              " 'lancaster',\n",
              " 'lazyimport',\n",
              " 'lfg',\n",
              " 'line_tokenize',\n",
              " 'linearlogic',\n",
              " 'load',\n",
              " 'load_parser',\n",
              " 'locale',\n",
              " 'log_likelihood',\n",
              " 'logic',\n",
              " 'mace',\n",
              " 'malt',\n",
              " 'map_tag',\n",
              " 'mapping',\n",
              " 'masi_distance',\n",
              " 'maxent',\n",
              " 'megam',\n",
              " 'memoize',\n",
              " 'metrics',\n",
              " 'misc',\n",
              " 'mwe',\n",
              " 'naivebayes',\n",
              " 'ne_chunk',\n",
              " 'ne_chunk_sents',\n",
              " 'ngrams',\n",
              " 'nonprojectivedependencyparser',\n",
              " 'nonterminals',\n",
              " 'numpy',\n",
              " 'os',\n",
              " 'pad_sequence',\n",
              " 'paice',\n",
              " 'parse',\n",
              " 'parse_sents',\n",
              " 'pchart',\n",
              " 'perceptron',\n",
              " 'pk',\n",
              " 'porter',\n",
              " 'pos_tag',\n",
              " 'pos_tag_sents',\n",
              " 'positivenaivebayes',\n",
              " 'pprint',\n",
              " 'pr',\n",
              " 'precision',\n",
              " 'presence',\n",
              " 'print_function',\n",
              " 'print_string',\n",
              " 'probability',\n",
              " 'projectivedependencyparser',\n",
              " 'prover9',\n",
              " 'punkt',\n",
              " 'py25',\n",
              " 'py26',\n",
              " 'py27',\n",
              " 'pydoc',\n",
              " 'python_2_unicode_compatible',\n",
              " 'raise_unorderable_types',\n",
              " 'ranks_from_scores',\n",
              " 'ranks_from_sequence',\n",
              " 're',\n",
              " 're_show',\n",
              " 'read_grammar',\n",
              " 'read_logic',\n",
              " 'read_valuation',\n",
              " 'recall',\n",
              " 'recursivedescent',\n",
              " 'regexp',\n",
              " 'regexp_span_tokenize',\n",
              " 'regexp_tokenize',\n",
              " 'register_tag',\n",
              " 'relextract',\n",
              " 'repp',\n",
              " 'resolution',\n",
              " 'ribes',\n",
              " 'ribes_score',\n",
              " 'root_semrep',\n",
              " 'rslp',\n",
              " 'rte_classifier',\n",
              " 'rte_classify',\n",
              " 'rte_features',\n",
              " 'rtuple',\n",
              " 'scikitlearn',\n",
              " 'scores',\n",
              " 'segmentation',\n",
              " 'sem',\n",
              " 'senna',\n",
              " 'sent_tokenize',\n",
              " 'sequential',\n",
              " 'set2rel',\n",
              " 'set_proxy',\n",
              " 'sexpr',\n",
              " 'sexpr_tokenize',\n",
              " 'shiftreduce',\n",
              " 'simple',\n",
              " 'sinica_parse',\n",
              " 'skipgrams',\n",
              " 'skolemize',\n",
              " 'slice_bounds',\n",
              " 'snowball',\n",
              " 'spearman',\n",
              " 'spearman_correlation',\n",
              " 'stack_decoder',\n",
              " 'stanford',\n",
              " 'stanford_segmenter',\n",
              " 'stem',\n",
              " 'str2tuple',\n",
              " 'string_span_tokenize',\n",
              " 'string_types',\n",
              " 'subprocess',\n",
              " 'subsumes',\n",
              " 'sum_logs',\n",
              " 'sys',\n",
              " 'tableau',\n",
              " 'tadm',\n",
              " 'tag',\n",
              " 'tagset_mapping',\n",
              " 'tagstr2tree',\n",
              " 'tbl',\n",
              " 'text',\n",
              " 'text_type',\n",
              " 'textcat',\n",
              " 'texttiling',\n",
              " 'textwrap',\n",
              " 'tkinter',\n",
              " 'tnt',\n",
              " 'tokenize',\n",
              " 'tokenwrap',\n",
              " 'toktok',\n",
              " 'toolbox',\n",
              " 'total_ordering',\n",
              " 'transitionparser',\n",
              " 'transitive_closure',\n",
              " 'translate',\n",
              " 'tree',\n",
              " 'tree2conllstr',\n",
              " 'tree2conlltags',\n",
              " 'treebank',\n",
              " 'treetransforms',\n",
              " 'trigrams',\n",
              " 'tuple2str',\n",
              " 'types',\n",
              " 'unify',\n",
              " 'unique_list',\n",
              " 'untag',\n",
              " 'usage',\n",
              " 'util',\n",
              " 'version_file',\n",
              " 'version_info',\n",
              " 'viterbi',\n",
              " 'weka',\n",
              " 'windowdiff',\n",
              " 'word_tokenize',\n",
              " 'wordnet',\n",
              " 'wordpunct_tokenize',\n",
              " 'wsd']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "dir(nltk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC2iONVVggWZ"
      },
      "source": [
        "### **What can you do with NLTK?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlRLIqTTggWb",
        "outputId": "4d4f862d-f8e3-437a-e5bc-74edb21c7b38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#as stopwords is not already downloaded in the nltk dir, lets download it by uncommenting\n",
        "#nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9sKa5ewggWa",
        "outputId": "fac0e51d-0c54-4164-90de-e2b798cb5388"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'herself', 'been', 'with', 'here', 'very', 'doesn', 'won']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#Basic functionality of nltk to get a glimpse of the tool capability.\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopwords.words('english')[0:500:25]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic functionality of nltk is checked! Hurrrrayyyyyy!!!!**"
      ],
      "metadata": {
        "id": "m6ryaX_uh8XU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NLP Basics: Reading and Cleaning Text - WHY?**"
      ],
      "metadata": {
        "id": "KbL39MreiFve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read in semi-structured text data\n",
        "# Read in the raw text\n",
        "rawData = open(\"SMSSpamCollection.tsv\").read()\n",
        "\n",
        "# Print the raw data\n",
        "rawData[0:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "_fxG5yvNiRlA",
        "outputId": "aed1b67b-4899-4bf6-9474-a19ec7032e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"ham\\tI've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\\nspam\\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\\nham\\tNah I don't think he goes to usf, he lives around here though\\nham\\tEven my brother is not like to speak with me. They treat me like aid\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Replace '\\n' with '\\t' to split this into a list and move forward further with splitting on '\\n'**"
      ],
      "metadata": {
        "id": "A6U6nIgzi7cA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parsedData = rawData.replace('\\t', '\\n').split('\\n')\n",
        "parsedData[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0osX2NfpjKOk",
        "outputId": "80fb7653-26f4-4456-c18b-cc8fafba75d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ham',\n",
              " \"I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\",\n",
              " 'spam',\n",
              " \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
              " 'ham']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract the data nto new list from parsedData**"
      ],
      "metadata": {
        "id": "wR9KcIhmjm6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labelList = parsedData[0::2]\n",
        "textList = parsedData[1::2]"
      ],
      "metadata": {
        "id": "_Oc9YF74jkse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if we call both the lists, it will return the last element called as we can see only textList below\n",
        "labelList[0:5]\n",
        "textList[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeLCuLoGkPZ2",
        "outputId": "d22fcfb5-4361-4da2-8525-1884c64229b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\",\n",
              " \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
              " \"Nah I don't think he goes to usf, he lives around here though\",\n",
              " 'Even my brother is not like to speak with me. They treat me like aids patent.',\n",
              " 'I HAVE A DATE ON SUNDAY WITH WILL!!']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#add the print statement otherwise jupiter notebook will return the latest statement only\n",
        "print(labelList[0:5])\n",
        "print(textList[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdB5wYvsj4q4",
        "outputId": "545eb97d-458d-4cfe-957a-9c806ae03e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ham', 'spam', 'ham', 'ham', 'ham']\n",
            "[\"I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\", \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", \"Nah I don't think he goes to usf, he lives around here though\", 'Even my brother is not like to speak with me. They treat me like aids patent.', 'I HAVE A DATE ON SUNDAY WITH WILL!!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Error is meant to be there, so that we can explore some error handling as well**"
      ],
      "metadata": {
        "id": "BHzwo-Ksoorx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Passing the dictionary with keys as label and values as lists containing the actual values\n",
        "import pandas as pd\n",
        "\n",
        "fullCorpus = pd.DataFrame({\n",
        "    'label': labelList,\n",
        "    'body_list': textList\n",
        "})\n",
        "\n",
        "fullCorpus.head() \n",
        "#this will give an error with \"ValueError: All arrays must be of the same length\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "UwH2sWxWkmVD",
        "outputId": "4c038b07-60a8-4d64-a0b4-e402a0db1d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-0cf568ded6e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m fullCorpus = pd.DataFrame({\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabelList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;34m'body_list'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtextList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m })\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     return arrays_to_mgr(\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m     )\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All arrays must be of the same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the length of both the lists\n",
        "print(len(labelList))\n",
        "print(len(textList))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7kAoUEgk3Uo",
        "outputId": "0b61ba6a-17f8-473e-9fd3-5d945298a0c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5571\n",
            "5570\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the last 5 items of the list\n",
        "print(labelList[-5:]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KoqIXWClMjT",
        "outputId": "3d2e61fd-5619-4e23-e90a-02cd3b6081a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ham', 'ham', 'ham', 'ham', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, here is the culprit causing the error as we have an empty item at the end of labelList which is causing the issue. "
      ],
      "metadata": {
        "id": "aU74xMlalTMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets try again leaving the last item.\n",
        "fullCorpus = pd.DataFrame({\n",
        "    'label': labelList[:-1],\n",
        "    'body_list': textList\n",
        "})\n",
        "\n",
        "fullCorpus.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "O9f6G_Gjlly7",
        "outputId": "a951e244-a290-4ee1-9f8c-6055c042011e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label                                          body_list\n",
              "0   ham  I've been searching for the right words to tha...\n",
              "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "2   ham  Nah I don't think he goes to usf, he lives aro...\n",
              "3   ham  Even my brother is not like to speak with me. ...\n",
              "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f78d73c0-f31d-476b-b018-795c1e6c5824\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f78d73c0-f31d-476b-b018-795c1e6c5824')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f78d73c0-f31d-476b-b018-795c1e6c5824 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f78d73c0-f31d-476b-b018-795c1e6c5824');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BINGO..!!! We got it!!!**\n",
        "**Now lets put this into a csv as we are dealing with tab delimited file, better to read it as csv**"
      ],
      "metadata": {
        "id": "fiiMygDBltX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"SMSSpamCollection.tsv\", sep=\"\\t\", header=None)\n",
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JXGYbof7mbuU",
        "outputId": "fe11dfe9-cd3a-42d4-e33f-d5517ce2a19e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0                                                  1\n",
              "0   ham  I've been searching for the right words to tha...\n",
              "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "2   ham  Nah I don't think he goes to usf, he lives aro...\n",
              "3   ham  Even my brother is not like to speak with me. ...\n",
              "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b7b39a9-a17d-4988-a870-0e68239fc1b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b7b39a9-a17d-4988-a870-0e68239fc1b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b7b39a9-a17d-4988-a870-0e68239fc1b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b7b39a9-a17d-4988-a870-0e68239fc1b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We can see that the the content of our tsv is read as csv and saved ito the \"dataset\" with no headers as tsv doesnt have header column.**"
      ],
      "metadata": {
        "id": "KCfXNzVDmf5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploring the dataset**"
      ],
      "metadata": {
        "id": "C5_hg48km-TN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets name our columns again as we want to see some headers\n",
        "fullCorpus.columns = ['label', 'body_text']\n",
        "\n",
        "fullCorpus.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fnmpAjF-nnNv",
        "outputId": "75508831-dae3-4dc2-e95c-9b17f021e309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label                                          body_text\n",
              "0   ham  I've been searching for the right words to tha...\n",
              "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "2   ham  Nah I don't think he goes to usf, he lives aro...\n",
              "3   ham  Even my brother is not like to speak with me. ...\n",
              "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1fa13fb1-d991-4b68-988e-14c2726ecc83\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1fa13fb1-d991-4b68-988e-14c2726ecc83')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1fa13fb1-d991-4b68-988e-14c2726ecc83 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1fa13fb1-d991-4b68-988e-14c2726ecc83');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the shape of the dataset?\n",
        "\n",
        "print(\"Input data has {} rows and {} columns\".format(len(fullCorpus), len(fullCorpus.columns)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsZ9tpESmvjj",
        "outputId": "eb37ccb9-4ea3-49f6-d23a-b380fcba2f85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data has 5570 rows and 2 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many spam/ham are there?\n",
        "\n",
        "print(\"Out of {} rows, {} are spam, {} are ham\".format(len(fullCorpus),\n",
        "                                                       len(fullCorpus[fullCorpus['label']=='spam']),\n",
        "                                                       len(fullCorpus[fullCorpus['label']=='ham'])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9MoAIy1ncou",
        "outputId": "0d990d48-f6d4-412c-a290-7932370795f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out of 5570 rows, 746 are spam, 4824 are ham\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How much missing data is there?\n",
        "\n",
        "print(\"Number of null in label: {}\".format(fullCorpus['label'].isnull().sum()))\n",
        "print(\"Number of null in text: {}\".format(fullCorpus['body_text'].isnull().sum()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bs4Vrf4nfCp",
        "outputId": "34348c7a-23d8-4651-8c5b-2e85df1e2c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of null in label: 0\n",
            "Number of null in text: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Learning how to use regular expressions**"
      ],
      "metadata": {
        "id": "IFuxclsjqafc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Using regular expressions in Python**\n",
        "\n",
        "Python's `re` package is the most commonly used regex resource. More details can be found [here](https://docs.python.org/3/library/re.html)."
      ],
      "metadata": {
        "id": "2tCoZ5E0qgOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. 'split' method splits the string we pass using regex**\n",
        "\n",
        "**2. 'findall' method from re package helps to find all the characters we use regex for.**\n",
        "- **'\\s'** is used to find all the single white spaces in the string\n",
        "- '**\\S**' is used to find all the non-white spaces characters in the string.\n",
        "> **Limitation** - it can't handle special characters\n",
        "- **'\\w'** is able to handle the special characters and return the cleaned string\n",
        "\n",
        "Examples are shown in this section."
      ],
      "metadata": {
        "id": "4ZfMKHnFtBqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "re_test = 'This is a made up string to test 2 different regex methods'\n",
        "re_test_messy = 'This      is a made up     string to test 2    different regex methods'\n",
        "re_test_messy1 = 'This-is-a-made/up.string*to>>>>test----2\"\"\"\"\"\"different~regex-methods'"
      ],
      "metadata": {
        "id": "BK-HvOBHqhJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Splitting a sentence into a list of words**"
      ],
      "metadata": {
        "id": "QvMOO48GqoJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "re.split('\\s',re_test) # '\\s' will ask python to look for single whitespace to split the string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-53RPagYqrUH",
        "outputId": "100e8506-662d-4ba8-f4dd-69c8ed1fbbed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'is',\n",
              " 'a',\n",
              " 'made',\n",
              " 'up',\n",
              " 'string',\n",
              " 'to',\n",
              " 'test',\n",
              " '2',\n",
              " 'different',\n",
              " 'regex',\n",
              " 'methods']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.split('\\s',re_test_messy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dxyGKjGrGTg",
        "outputId": "5c770a1e-355d-4e57-a00b-cdd4a01131a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " 'is',\n",
              " 'a',\n",
              " 'made',\n",
              " 'up',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " 'string',\n",
              " 'to',\n",
              " 'test',\n",
              " '2',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " 'different',\n",
              " 'regex',\n",
              " 'methods']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, since we have more than one white spaces in the string re_test_messy, it won't split the string with Regex '\\s' properly.\n",
        "So, lets tell python to look for more than one whitespaces by adding a '+' sign as shown below."
      ],
      "metadata": {
        "id": "4jS4Mk2oraif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "re.split('\\s+',re_test_messy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEusbkqfrquc",
        "outputId": "3465a41d-a683-4c1b-bab7-1734a4c2feba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'is',\n",
              " 'a',\n",
              " 'made',\n",
              " 'up',\n",
              " 'string',\n",
              " 'to',\n",
              " 'test',\n",
              " '2',\n",
              " 'different',\n",
              " 'regex',\n",
              " 'methods']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perfect! That did the trick!"
      ],
      "metadata": {
        "id": "OPQMPRDYruzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "re.split('\\s+', re_test_messy1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDiJmwrjr4AC",
        "outputId": "c67d0288-bf37-4eca-f2f6-7a2e8db7e178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This-is-a-made/up.string*to>>>>test----2\"\"\"\"\"\"different~regex-methods']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\\'W+' will search for any non-word character and use that to split the string. \n",
        "#This is more robust than handling whitespaces alone as we have to deal with special characters.\n",
        "re.split('\\W+', re_test_messy1) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0zj5KbVsGzu",
        "outputId": "bacc0339-ca45-4f06-8d1e-85f308f5b23a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'is',\n",
              " 'a',\n",
              " 'made',\n",
              " 'up',\n",
              " 'string',\n",
              " 'to',\n",
              " 'test',\n",
              " '2',\n",
              " 'different',\n",
              " 'regex',\n",
              " 'methods']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall('\\S+', re_test) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbkE48yosoq6",
        "outputId": "5d80d616-c44d-4964-8d53-5177c69e3dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'is',\n",
              " 'a',\n",
              " 'made',\n",
              " 'up',\n",
              " 'string',\n",
              " 'to',\n",
              " 'test',\n",
              " '2',\n",
              " 'different',\n",
              " 'regex',\n",
              " 'methods']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall('\\S+', re_test_messy) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVwfdSWvu3XW",
        "outputId": "9691dad9-06e8-4892-caa6-28d88307f7d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'is',\n",
              " 'a',\n",
              " 'made',\n",
              " 'up',\n",
              " 'string',\n",
              " 'to',\n",
              " 'test',\n",
              " '2',\n",
              " 'different',\n",
              " 'regex',\n",
              " 'methods']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall('\\S+', re_test_messy1) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-_hlsEwu6Iv",
        "outputId": "3a5f5c28-e7f4-4bf7-8a1d-62a529b05a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This-is-a-made/up.string*to>>>>test----2\"\"\"\"\"\"different~regex-methods']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! **\"Didn't work well!\"** !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
      ],
      "metadata": {
        "id": "ramzHY1eu_im"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#'\\w' will look for one or more word characters and will find the tokens that resembles a word - look for letters\n",
        "re.findall('\\w+', re_test_messy1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KMtwvYFvKLj",
        "outputId": "9941ca12-5216-4cb6-8bab-bed6e5c55a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'is',\n",
              " 'a',\n",
              " 'made',\n",
              " 'up',\n",
              " 'string',\n",
              " 'to',\n",
              " 'test',\n",
              " '2',\n",
              " 'different',\n",
              " 'regex',\n",
              " 'methods']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Replacing a specific string**"
      ],
      "metadata": {
        "id": "r2Dabe0ary36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pep8_test = 'I try to follow PEP8 guidelines'\n",
        "pep7_test = 'I try to follow PEP7 guidelines'\n",
        "peep8_test = 'I try to follow PEEP8 guidelines'"
      ],
      "metadata": {
        "id": "ixn4QF2AxTrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#REGEX is case-sensitive\n",
        "import re\n",
        "re.findall('[a-z]+', pep8_test)\n",
        "\n",
        "#here, it missed 'PEP8' and 'I' as they are in caps!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-yAKsNSxdsx",
        "outputId": "0a687bef-ea12-46b6-9376-75faef9d2504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['try', 'to', 'follow', 'guidelines']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here it missed all small cap letters and also digit8\n",
        "re.findall('[A-Z]+', pep8_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnHCUFC4x9o3",
        "outputId": "9ed16c2c-8340-4d11-ebd8-167dce0e24aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'PEP']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall('[A-Z]+[0-9]+', pep8_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFSxiW4byTs3",
        "outputId": "6350aafc-b2a6-4a13-9dda-32d7a9462a9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PEP8']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the following code should find 'PEEP8' and replace it with the string enclosed\n",
        "re.sub('[A-Z]+[0-9]+', 'PEP8 Python Styleguide', peep8_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FAec3fp5ylsx",
        "outputId": "dca62bce-1907-4196-9fd0-be50096bc4d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I try to follow PEP8 Python Styleguide guidelines'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Other examples of regex methods**\n",
        "\n",
        "- re.search()\n",
        "- re.match()\n",
        "- re.fullmatch()\n",
        "- re.finditer()\n",
        "- re.escape()"
      ],
      "metadata": {
        "id": "9c8jLi7LxYYq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mze3tplIzcgr"
      },
      "source": [
        "# **NLP Basics: Implementing a pipeline to clean text**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWAWFLwyzchG"
      },
      "source": [
        "### Pre-processing text data\n",
        "\n",
        "Cleaning up the text data is necessary to highlight attributes that you're going to want your machine learning system to pick up on. Cleaning (or pre-processing) the data typically consists of a number of steps:\n",
        "1. **Remove punctuation**\n",
        "2. **Tokenization**\n",
        "3. **Remove stopwords**\n",
        "4. Lemmatize/Stem\n",
        "\n",
        "The first three steps are covered in this chapter as they're implemented in pretty much any text cleaning pipeline. Lemmatizing and stemming are covered in the next chapter as they're helpful but not critical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaTYrTXKzchL",
        "outputId": "1fa60788-f6db-4957-eeb4-c93b96ce504e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label  \\\n",
              "0   ham   \n",
              "1  spam   \n",
              "2   ham   \n",
              "3   ham   \n",
              "4   ham   \n",
              "\n",
              "                                                                                             body_text  \n",
              "0  I've been searching for the right words to thank you for this breather. I promise i wont take yo...  \n",
              "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
              "2                                        Nah I don't think he goes to usf, he lives around here though  \n",
              "3                        Even my brother is not like to speak with me. They treat me like aids patent.  \n",
              "4                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86051688-af1c-46bc-afd2-9c2c4b958434\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86051688-af1c-46bc-afd2-9c2c4b958434')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86051688-af1c-46bc-afd2-9c2c4b958434 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86051688-af1c-46bc-afd2-9c2c4b958434');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "\n",
        "data = pd.read_csv(\"SMSSpamCollection.tsv\", sep='\\t', header=None)\n",
        "data.columns = ['label', 'body_text']\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkLmUwKfzchW",
        "outputId": "5ba2cfcb-a891-4685-aa1d-c2e359151066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label  \\\n",
              "0   ham   \n",
              "1  spam   \n",
              "2   ham   \n",
              "3   ham   \n",
              "4   ham   \n",
              "\n",
              "                                                                                             body_text  \\\n",
              "0  I've been searching for the right words to thank you for this breather. I promise i wont take yo...   \n",
              "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
              "2                                        Nah I don't think he goes to usf, he lives around here though   \n",
              "3                        Even my brother is not like to speak with me. They treat me like aids patent.   \n",
              "4                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
              "\n",
              "                                                                                      body_text_nostop  \n",
              "0  ['ive', 'searching', 'right', 'words', 'thank', 'breather', 'promise', 'wont', 'take', 'help', '...  \n",
              "1  ['free', 'entry', '2', 'wkly', 'comp', 'win', 'fa', 'cup', 'final', 'tkts', '21st', 'may', '2005...  \n",
              "2                                 ['nah', 'dont', 'think', 'goes', 'usf', 'lives', 'around', 'though']  \n",
              "3                              ['even', 'brother', 'like', 'speak', 'treat', 'like', 'aids', 'patent']  \n",
              "4                                                                                   ['date', 'sunday']  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79dc2a59-e942-4264-9e90-71857abb0762\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "      <th>body_text_nostop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
              "      <td>['ive', 'searching', 'right', 'words', 'thank', 'breather', 'promise', 'wont', 'take', 'help', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "      <td>['free', 'entry', '2', 'wkly', 'comp', 'win', 'fa', 'cup', 'final', 'tkts', '21st', 'may', '2005...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "      <td>['nah', 'dont', 'think', 'goes', 'usf', 'lives', 'around', 'though']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
              "      <td>['even', 'brother', 'like', 'speak', 'treat', 'like', 'aids', 'patent']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "      <td>['date', 'sunday']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79dc2a59-e942-4264-9e90-71857abb0762')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-79dc2a59-e942-4264-9e90-71857abb0762 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-79dc2a59-e942-4264-9e90-71857abb0762');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# What does the cleaned version look like?\n",
        "data_cleaned = pd.read_csv(\"SMSSpamCollection_cleaned.tsv\", sep='\\t')\n",
        "data_cleaned.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSPatVgJzchZ"
      },
      "source": [
        "### **Remove punctuation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jIzXoCVzche",
        "outputId": "18f8a7e3-f07c-4c22-82dc-aa8d595fcac0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# There are so many punctuations in textual data that we know is same but python doesnt know how to distinuguish.\n",
        "import string\n",
        "string.punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rP3aeSJjzchk",
        "outputId": "09c884df-84f6-4a80-b9c1-d2cc0ac939a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "#For example, Python thinks the below strings are unequal.\n",
        "\"I like NLP.\" == \"I like NLP\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hence, its necessary to remove punctuation in order to clean textual data."
      ],
      "metadata": {
        "id": "nnq7Eca_2D5E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **List Comprehension**"
      ],
      "metadata": {
        "id": "0ejeaJhi2NBA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "List comprehension makes it easy to cycle through elements, check if they meet some condition, and then just return if they do meet that condition. So, let's go ahead and build this function. "
      ],
      "metadata": {
        "id": "Fy2y564T2eiw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpAeWMwGzchn",
        "outputId": "7656d8d2-ad05-4df6-c766-fd9b16b50d53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label  \\\n",
              "0   ham   \n",
              "1  spam   \n",
              "2   ham   \n",
              "3   ham   \n",
              "4   ham   \n",
              "\n",
              "                                                                                             body_text  \\\n",
              "0  I've been searching for the right words to thank you for this breather. I promise i wont take yo...   \n",
              "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
              "2                                        Nah I don't think he goes to usf, he lives around here though   \n",
              "3                        Even my brother is not like to speak with me. They treat me like aids patent.   \n",
              "4                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
              "\n",
              "                                                                                       body_text_clean  \n",
              "0  [I, v, e,  , b, e, e, n,  , s, e, a, r, c, h, i, n, g,  , f, o, r,  , t, h, e,  , r, i, g, h, t,...  \n",
              "1  [F, r, e, e,  , e, n, t, r, y,  , i, n,  , 2,  , a,  , w, k, l, y,  , c, o, m, p,  , t, o,  , w,...  \n",
              "2  [N, a, h,  , I,  , d, o, n, t,  , t, h, i, n, k,  , h, e,  , g, o, e, s,  , t, o,  , u, s, f,  ,...  \n",
              "3  [E, v, e, n,  , m, y,  , b, r, o, t, h, e, r,  , i, s,  , n, o, t,  , l, i, k, e,  , t, o,  , s,...  \n",
              "4  [I,  , H, A, V, E,  , A,  , D, A, T, E,  , O, N,  , S, U, N, D, A, Y,  , W, I, T, H,  , W, I, L, L]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4ddb24c-33dd-4fe5-95ae-dad89fa60798\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "      <th>body_text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
              "      <td>[I, v, e,  , b, e, e, n,  , s, e, a, r, c, h, i, n, g,  , f, o, r,  , t, h, e,  , r, i, g, h, t,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "      <td>[F, r, e, e,  , e, n, t, r, y,  , i, n,  , 2,  , a,  , w, k, l, y,  , c, o, m, p,  , t, o,  , w,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "      <td>[N, a, h,  , I,  , d, o, n, t,  , t, h, i, n, k,  , h, e,  , g, o, e, s,  , t, o,  , u, s, f,  ,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
              "      <td>[E, v, e, n,  , m, y,  , b, r, o, t, h, e, r,  , i, s,  , n, o, t,  , l, i, k, e,  , t, o,  , s,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "      <td>[I,  , H, A, V, E,  , A,  , D, A, T, E,  , O, N,  , S, U, N, D, A, Y,  , W, I, T, H,  , W, I, L, L]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4ddb24c-33dd-4fe5-95ae-dad89fa60798')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4ddb24c-33dd-4fe5-95ae-dad89fa60798 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4ddb24c-33dd-4fe5-95ae-dad89fa60798');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "def remove_punct(text):\n",
        "    text_nopunct = [char for char in text if char not in string.punctuation]\n",
        "    return text_nopunct\n",
        "\n",
        "data['body_text_clean'] = data['body_text'].apply(lambda x: remove_punct(x))\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " So, this is a reminder that list comprehension will return a list, and because we explicitly told it to evaluate **each character** to see if it's in the list of punctuation, when it's done checking, it'll just return that as a **single element** in the list. So, in order to fix this, we're going to wrap this in a join function. **It'll take this list that this list comprehension is generating and it will just join each individual element to one another.**"
      ],
      "metadata": {
        "id": "-3VJuVuO3VO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##join on \"\" i.e., nothing so that it understands no additional space has to be read between letters\n",
        "def remove_punct(text):\n",
        "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation]) \n",
        "    return text_nopunct\n",
        "\n",
        "data['body_text_clean'] = data['body_text'].apply(lambda x: remove_punct(x))\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "S_c7PG1k3q2n",
        "outputId": "b4c7fad0-df14-4ed2-9a40-e869ed3beddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label  \\\n",
              "0   ham   \n",
              "1  spam   \n",
              "2   ham   \n",
              "3   ham   \n",
              "4   ham   \n",
              "\n",
              "                                                                                             body_text  \\\n",
              "0  I've been searching for the right words to thank you for this breather. I promise i wont take yo...   \n",
              "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
              "2                                        Nah I don't think he goes to usf, he lives around here though   \n",
              "3                        Even my brother is not like to speak with me. They treat me like aids patent.   \n",
              "4                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
              "\n",
              "                                                                                       body_text_clean  \n",
              "0  Ive been searching for the right words to thank you for this breather I promise i wont take your...  \n",
              "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...  \n",
              "2                                          Nah I dont think he goes to usf he lives around here though  \n",
              "3                          Even my brother is not like to speak with me They treat me like aids patent  \n",
              "4                                                                    I HAVE A DATE ON SUNDAY WITH WILL  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5911631d-eced-4b33-977e-58efce0c0f35\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "      <th>body_text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
              "      <td>Ive been searching for the right words to thank you for this breather I promise i wont take your...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
              "      <td>Even my brother is not like to speak with me They treat me like aids patent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5911631d-eced-4b33-977e-58efce0c0f35')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5911631d-eced-4b33-977e-58efce0c0f35 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5911631d-eced-4b33-977e-58efce0c0f35');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cE1mXkpzcht"
      },
      "source": [
        "### **Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yAxMXse4zchv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "8283adc5-73bf-4ff0-b2ad-83ef85c9d505"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label  \\\n",
              "0   ham   \n",
              "1  spam   \n",
              "2   ham   \n",
              "3   ham   \n",
              "4   ham   \n",
              "\n",
              "                                                                                             body_text  \\\n",
              "0  I've been searching for the right words to thank you for this breather. I promise i wont take yo...   \n",
              "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
              "2                                        Nah I don't think he goes to usf, he lives around here though   \n",
              "3                        Even my brother is not like to speak with me. They treat me like aids patent.   \n",
              "4                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
              "\n",
              "                                                                                       body_text_clean  \\\n",
              "0  Ive been searching for the right words to thank you for this breather I promise i wont take your...   \n",
              "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...   \n",
              "2                                          Nah I dont think he goes to usf he lives around here though   \n",
              "3                          Even my brother is not like to speak with me They treat me like aids patent   \n",
              "4                                                                    I HAVE A DATE ON SUNDAY WITH WILL   \n",
              "\n",
              "                                                                                   body_text_tokenized  \n",
              "0  [ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, ...  \n",
              "1  [free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...  \n",
              "2                            [nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]  \n",
              "3         [even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]  \n",
              "4                                                           [i, have, a, date, on, sunday, with, will]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e8248900-b85e-4a16-b704-c335f71604ce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
              "      <td>Ive been searching for the right words to thank you for this breather I promise i wont take your...</td>\n",
              "      <td>[ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
              "      <td>[nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
              "      <td>Even my brother is not like to speak with me They treat me like aids patent</td>\n",
              "      <td>[even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
              "      <td>[i, have, a, date, on, sunday, with, will]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8248900-b85e-4a16-b704-c335f71604ce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e8248900-b85e-4a16-b704-c335f71604ce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e8248900-b85e-4a16-b704-c335f71604ce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def tokenize(text):\n",
        "    tokens = re.split('\\W+', text)\n",
        "    return tokens\n",
        "\n",
        "data['body_text_tokenized'] = data['body_text_clean'].apply(lambda x: tokenize(x.lower()))\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'NLP' == 'nlp' "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pZU1dfd6-e3",
        "outputId": "c2ff21d7-b4c2-4c1c-b318-456b4e531733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Now, Python is case-sensitive, so if you give it capital NLP, and ask if its the same as lowercase nlp, we know to us, that's basically the same thing, but if you run that for Python, Python says those are two different things. So when we get in to further steps, now Python is seeing capital NLP is something totally different than lowercase nlp, and it has to learn that those things are closely related, but we don't want it to consume its resources by learning that those things are related, we want it to explicitly tell it that those are the same things. So that's why we apply this .lower method.\n",
        "\n",
        "\n",
        "  So now we have a nice clean list of words without any punctuation. So now Python knows the tokens or components that it's supposed to be looking at. The next step is going to be removing some of the more irrelevant words in these lists."
      ],
      "metadata": {
        "id": "GjeghhiU7blZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgqR2bnHzchz"
      },
      "source": [
        "### **Remove stopwords**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've removed punctuation and tokenized to create a list of words out of a sentence. The last step in cleaning up this data is to remove stopwords. Now we've discussed stopwords previously. They are commonly-used words like the, but, if, that don't contribute much to the meaning of a sentence. So we want to remove them, to limit the number of tokens Python actually has to look at when building our model. For instance, take the sentence, I am learning NLP. After tokenizing, it would have four tokens, I, am, learning, and NLP. Then after removing stopwords, instead of a list with four tokens, you're now left with just learning and NLP."
      ],
      "metadata": {
        "id": "mCHWrcRq8Q8A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3rCqUxPt7y02"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "\n",
        "stopword = nltk.corpus.stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuwjDSAn7y04",
        "outputId": "19eb84a6-b15d-4668-f040-b94776e1f742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label  \\\n",
              "0   ham   \n",
              "1  spam   \n",
              "2   ham   \n",
              "3   ham   \n",
              "4   ham   \n",
              "\n",
              "                                                                                             body_text  \\\n",
              "0  I've been searching for the right words to thank you for this breather. I promise i wont take yo...   \n",
              "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
              "2                                        Nah I don't think he goes to usf, he lives around here though   \n",
              "3                        Even my brother is not like to speak with me. They treat me like aids patent.   \n",
              "4                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
              "\n",
              "                                                                                       body_text_clean  \\\n",
              "0  Ive been searching for the right words to thank you for this breather I promise i wont take your...   \n",
              "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...   \n",
              "2                                          Nah I dont think he goes to usf he lives around here though   \n",
              "3                          Even my brother is not like to speak with me They treat me like aids patent   \n",
              "4                                                                    I HAVE A DATE ON SUNDAY WITH WILL   \n",
              "\n",
              "                                                                                   body_text_tokenized  \\\n",
              "0  [ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, ...   \n",
              "1  [free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...   \n",
              "2                            [nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]   \n",
              "3         [even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]   \n",
              "4                                                           [i, have, a, date, on, sunday, with, will]   \n",
              "\n",
              "                                                                                      body_text_nostop  \n",
              "0  [ive, searching, right, words, thank, breather, promise, wont, take, help, granted, fulfil, prom...  \n",
              "1  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...  \n",
              "2                                                 [nah, dont, think, goes, usf, lives, around, though]  \n",
              "3                                              [even, brother, like, speak, treat, like, aids, patent]  \n",
              "4                                                                                       [date, sunday]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-592b11e9-3f16-4170-b76f-f0ec69eef9a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "      <th>body_text_nostop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
              "      <td>Ive been searching for the right words to thank you for this breather I promise i wont take your...</td>\n",
              "      <td>[ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, ...</td>\n",
              "      <td>[ive, searching, right, words, thank, breather, promise, wont, take, help, granted, fulfil, prom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
              "      <td>[nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
              "      <td>[nah, dont, think, goes, usf, lives, around, though]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
              "      <td>Even my brother is not like to speak with me They treat me like aids patent</td>\n",
              "      <td>[even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]</td>\n",
              "      <td>[even, brother, like, speak, treat, like, aids, patent]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
              "      <td>[i, have, a, date, on, sunday, with, will]</td>\n",
              "      <td>[date, sunday]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-592b11e9-3f16-4170-b76f-f0ec69eef9a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-592b11e9-3f16-4170-b76f-f0ec69eef9a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-592b11e9-3f16-4170-b76f-f0ec69eef9a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "# Same like above list comprehension for our function\n",
        "def remove_stopwords(tokenized_list):\n",
        "    text = [word for word in tokenized_list if word not in stopword]\n",
        "    return text\n",
        "\n",
        "data['body_text_nostop'] = data['body_text_tokenized'].apply(lambda x: remove_stopwords(x))\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Supplemental Data Cleaning: Using Stemming**"
      ],
      "metadata": {
        "id": "f7ZBDacLHi0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming is an NLP process that reduces the inflection in words to their root forms which in turn helps to preprocess text, words, and documents for text normalization.**\n",
        "\n",
        "Why does it help us in model building?\n",
        "Stemmers are the root words and benefits of using a stemmer are:\n",
        "\n",
        "- Reduces the corpus of words the model is exposed to\n",
        "- Explicitly correlates words with similar meanings\n",
        "\n",
        "What are some stemmers?\n",
        "\n",
        "- Porter Stemmer\n",
        "- Snowball stemmer\n",
        "- Lancaster Stemmer\n",
        "- Regex-Based Stemmer\n"
      ],
      "metadata": {
        "id": "m_lb6zMLHqyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test Porter Stemmer**"
      ],
      "metadata": {
        "id": "9Xb6J3XIIwmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "ps = nltk.PorterStemmer()"
      ],
      "metadata": {
        "id": "FAua32zAHtV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(ps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raRQDmDKI22T",
        "outputId": "9d591781-c986-4b21-d649-7c2d4a6c6fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MARTIN_EXTENSIONS',\n",
              " 'NLTK_EXTENSIONS',\n",
              " 'ORIGINAL_ALGORITHM',\n",
              " '__abstractmethods__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__unicode__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_apply_rule_list',\n",
              " '_contains_vowel',\n",
              " '_ends_cvc',\n",
              " '_ends_double_consonant',\n",
              " '_has_positive_measure',\n",
              " '_is_consonant',\n",
              " '_measure',\n",
              " '_replace_suffix',\n",
              " '_step1a',\n",
              " '_step1b',\n",
              " '_step1c',\n",
              " '_step2',\n",
              " '_step3',\n",
              " '_step4',\n",
              " '_step5a',\n",
              " '_step5b',\n",
              " 'mode',\n",
              " 'pool',\n",
              " 'stem',\n",
              " 'unicode_repr',\n",
              " 'vowels']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ps.stem('grows'))\n",
        "print(ps.stem('growing'))\n",
        "print(ps.stem('grow'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PkB3xipI5w6",
        "outputId": "b5d80827-603b-46d5-aeda-410e7c5bc5ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grow\n",
            "grow\n",
            "grow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtv57p7UHciT",
        "outputId": "65cd3722-f360-43b0-f0a5-c3b100447344",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run\n",
            "run\n",
            "runner\n"
          ]
        }
      ],
      "source": [
        "print(ps.stem('run'))\n",
        "print(ps.stem('running'))\n",
        "print(ps.stem('runner'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could see how all three of these might be reduced down to just run. Even though the first two are actions and the last one describes a person. So the stemmer can actually tell that the first two are different than the last one in some way. So stemmers certainly aren't perfect, but they still do a pretty good job of identifying words that have the same meaning."
      ],
      "metadata": {
        "id": "5YBwl3wbJtGW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Read in raw text**"
      ],
      "metadata": {
        "id": "x_XPQqdsKCyb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctn4-jUVHciU",
        "outputId": "ea24443a-050e-4faf-d691-171d400e5c90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label  \\\n",
              "0  spam   \n",
              "1   ham   \n",
              "2   ham   \n",
              "3   ham   \n",
              "4   ham   \n",
              "\n",
              "                                                                                             body_text  \n",
              "0  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
              "1                                        Nah I don't think he goes to usf, he lives around here though  \n",
              "2                        Even my brother is not like to speak with me. They treat me like aids patent.  \n",
              "3                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!  \n",
              "4  As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your call...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73520212-ab6d-497a-943e-1de6fbc59828\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your call...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73520212-ab6d-497a-943e-1de6fbc59828')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73520212-ab6d-497a-943e-1de6fbc59828 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73520212-ab6d-497a-943e-1de6fbc59828');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "data = pd.read_csv(\"SMSSpamCollection.tsv\", sep='\\t')\n",
        "data.columns = ['label', 'body_text']\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XXLUGc3HciV"
      },
      "source": [
        "### **Clean up text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXyLS7FLHciV",
        "outputId": "97e593aa-dc9b-433a-fb46-f5a3b2bde083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label  \\\n",
              "0  spam   \n",
              "1   ham   \n",
              "2   ham   \n",
              "3   ham   \n",
              "4   ham   \n",
              "\n",
              "                                                                                             body_text  \\\n",
              "0  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
              "1                                        Nah I don't think he goes to usf, he lives around here though   \n",
              "2                        Even my brother is not like to speak with me. They treat me like aids patent.   \n",
              "3                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
              "4  As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your call...   \n",
              "\n",
              "                                                                                      body_text_nostop  \n",
              "0  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...  \n",
              "1                                                 [nah, dont, think, goes, usf, lives, around, though]  \n",
              "2                                              [even, brother, like, speak, treat, like, aids, patent]  \n",
              "3                                                                                       [date, sunday]  \n",
              "4  [per, request, melle, melle, oru, minnaminunginte, nurungu, vettam, set, callertune, callers, pr...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23f29dda-28d1-4e26-9664-38cb178b06cf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "      <th>body_text_nostop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "      <td>[nah, dont, think, goes, usf, lives, around, though]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
              "      <td>[even, brother, like, speak, treat, like, aids, patent]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "      <td>[date, sunday]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your call...</td>\n",
              "      <td>[per, request, melle, melle, oru, minnaminunginte, nurungu, vettam, set, callertune, callers, pr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23f29dda-28d1-4e26-9664-38cb178b06cf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-23f29dda-28d1-4e26-9664-38cb178b06cf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-23f29dda-28d1-4e26-9664-38cb178b06cf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "#Same function combining all the cleaning operations into one single function.\n",
        "def clean_text(text):\n",
        "    text = \"\".join([word for word in text if word not in string.punctuation])\n",
        "    tokens = re.split('\\W+', text)\n",
        "    text = [word for word in tokens if word not in stopwords]\n",
        "    return text\n",
        "\n",
        "data['body_text_nostop'] = data['body_text'].apply(lambda x: clean_text(x.lower()))\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JHZun1sHciW"
      },
      "source": [
        "### **Stem text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_Z3ABH5HciW",
        "outputId": "deecd5bb-e72a-4b9d-ed5c-fa5e66fccc2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label  \\\n",
              "0  spam   \n",
              "1   ham   \n",
              "2   ham   \n",
              "3   ham   \n",
              "4   ham   \n",
              "\n",
              "                                                                                             body_text  \\\n",
              "0  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
              "1                                        Nah I don't think he goes to usf, he lives around here though   \n",
              "2                        Even my brother is not like to speak with me. They treat me like aids patent.   \n",
              "3                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
              "4  As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your call...   \n",
              "\n",
              "                                                                                      body_text_nostop  \\\n",
              "0  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...   \n",
              "1                                                 [nah, dont, think, goes, usf, lives, around, though]   \n",
              "2                                              [even, brother, like, speak, treat, like, aids, patent]   \n",
              "3                                                                                       [date, sunday]   \n",
              "4  [per, request, melle, melle, oru, minnaminunginte, nurungu, vettam, set, callertune, callers, pr...   \n",
              "\n",
              "                                                                                     body_text_stemmed  \n",
              "0  [free, entri, 2, wkli, comp, win, fa, cup, final, tkt, 21st, may, 2005, text, fa, 87121, receiv,...  \n",
              "1                                                   [nah, dont, think, goe, usf, live, around, though]  \n",
              "2                                               [even, brother, like, speak, treat, like, aid, patent]  \n",
              "3                                                                                       [date, sunday]  \n",
              "4  [per, request, mell, mell, oru, minnaminungint, nurungu, vettam, set, callertun, caller, press, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4faa8d5-b133-4f4e-8eb1-b4f43e8289b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "      <th>body_text_nostop</th>\n",
              "      <th>body_text_stemmed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...</td>\n",
              "      <td>[free, entri, 2, wkli, comp, win, fa, cup, final, tkt, 21st, may, 2005, text, fa, 87121, receiv,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "      <td>[nah, dont, think, goes, usf, lives, around, though]</td>\n",
              "      <td>[nah, dont, think, goe, usf, live, around, though]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
              "      <td>[even, brother, like, speak, treat, like, aids, patent]</td>\n",
              "      <td>[even, brother, like, speak, treat, like, aid, patent]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "      <td>[date, sunday]</td>\n",
              "      <td>[date, sunday]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your call...</td>\n",
              "      <td>[per, request, melle, melle, oru, minnaminunginte, nurungu, vettam, set, callertune, callers, pr...</td>\n",
              "      <td>[per, request, mell, mell, oru, minnaminungint, nurungu, vettam, set, callertun, caller, press, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4faa8d5-b133-4f4e-8eb1-b4f43e8289b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4faa8d5-b133-4f4e-8eb1-b4f43e8289b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4faa8d5-b133-4f4e-8eb1-b4f43e8289b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "def stemming(tokenized_text):\n",
        "    text = [ps.stem(word) for word in tokenized_text]\n",
        "    return text\n",
        "\n",
        "data['body_text_stemmed'] = data['body_text_nostop'].apply(lambda x: stemming(x))\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemmer won't do a great job with slang or abbreviations. So it's probably not a great fit for a text message data set.For example:\n",
        "First, entry is changed to entri with an i so it could also accommodate plural, entries. Same thing with wkli. Another one is on the second line, lives is reduced down to live.\n",
        " Stemming helps us reduce the corpus of words that the models are exposed to, and it explicitly correlates words with similar meaning.\n"
      ],
      "metadata": {
        "id": "92wUxyh1K9bv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyI1gu85La_m"
      },
      "source": [
        "# **Supplemental Data Cleaning: Using a Lemmatizer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j9eg6shLa_s"
      },
      "source": [
        "### **Test out WordNet lemmatizer (read more about WordNet [here](https://wordnet.princeton.edu/))**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WVunr0bgLa_s"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wn = nltk.WordNetLemmatizer()\n",
        "ps = nltk.PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoLMG3bKLa_u",
        "outputId": "8262d0d8-ccad-4fab-c1c4-c65588c64e4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__unicode__',\n",
              " '__weakref__',\n",
              " 'lemmatize',\n",
              " 'unicode_repr']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "dir(wn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4JbV7rlN6KB",
        "outputId": "e7199547-70d6-4c23-dab9-4326c6785c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvH7GEzqLa_v",
        "outputId": "18a45fd9-77fa-4890-9291-06891348371a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean\n",
            "mean\n"
          ]
        }
      ],
      "source": [
        "print(ps.stem('meanness'))\n",
        "print(ps.stem('meaning'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ph3l0Q2VLa_v",
        "outputId": "38043cf0-6c19-4780-87c9-36c1b58b0dd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "meanness\n",
            "meaning\n"
          ]
        }
      ],
      "source": [
        "print(wn.lemmatize('meanness'))\n",
        "print(wn.lemmatize('meaning'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First, stemming uses the algorithmic approach so it's only concerned with the string that it's given, and it will essentially chop off the suffix. Lemmatizing is a little bit more complex in that it searches the corpus to find related words and condense it down to the core concept. The problem is that if this word isn't in the corpus, then it will just return the original word, so that's what's happening here.**"
      ],
      "metadata": {
        "id": "zuA58Zy3OM8_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXm7YNS_La_w",
        "outputId": "3a3477fb-0106-44a7-c47a-7e27c0502998",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "goos\n",
            "gees\n"
          ]
        }
      ],
      "source": [
        "print(ps.stem('goose'))\n",
        "print(ps.stem('geese'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4k1e6kSLa_x",
        "outputId": "23c83142-acc2-458c-e1a6-ccbde1ef3061",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "goose\n",
            "goose\n"
          ]
        }
      ],
      "source": [
        "print(wn.lemmatize('goose'))\n",
        "print(wn.lemmatize('geese'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFrxRYWbLa_x"
      },
      "source": [
        "### Read in raw text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PAdRM8jLa_y",
        "outputId": "e076ef5e-6071-473e-9853-1581539a0530"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your call...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  \\\n",
              "0  spam   \n",
              "1   ham   \n",
              "2   ham   \n",
              "3   ham   \n",
              "4   ham   \n",
              "\n",
              "                                                                                             body_text  \n",
              "0  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
              "1                                        Nah I don't think he goes to usf, he lives around here though  \n",
              "2                        Even my brother is not like to speak with me. They treat me like aids patent.  \n",
              "3                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!  \n",
              "4  As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your call...  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "data = pd.read_csv(\"SMSSpamCollection.tsv\", sep='\\t')\n",
        "data.columns = ['label', 'body_text']\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aK6tyY_7La_y"
      },
      "source": [
        "### Clean up text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVh9IGrqLa_z",
        "outputId": "c5bc6011-0f5e-4888-ac74-c61704dffb10"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "      <th>body_text_nostop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "      <td>[nah, dont, think, goes, usf, lives, around, though]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
              "      <td>[even, brother, like, speak, treat, like, aids, patent]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "      <td>[date, sunday]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your call...</td>\n",
              "      <td>[per, request, melle, melle, oru, minnaminunginte, nurungu, vettam, set, callertune, callers, pr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  \\\n",
              "0  spam   \n",
              "1   ham   \n",
              "2   ham   \n",
              "3   ham   \n",
              "4   ham   \n",
              "\n",
              "                                                                                             body_text  \\\n",
              "0  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
              "1                                        Nah I don't think he goes to usf, he lives around here though   \n",
              "2                        Even my brother is not like to speak with me. They treat me like aids patent.   \n",
              "3                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
              "4  As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your call...   \n",
              "\n",
              "                                                                                      body_text_nostop  \n",
              "0  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...  \n",
              "1                                                 [nah, dont, think, goes, usf, lives, around, though]  \n",
              "2                                              [even, brother, like, speak, treat, like, aids, patent]  \n",
              "3                                                                                       [date, sunday]  \n",
              "4  [per, request, melle, melle, oru, minnaminunginte, nurungu, vettam, set, callertune, callers, pr...  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def clean_text(text):\n",
        "    text = \"\".join([word for word in text if word not in string.punctuation])\n",
        "    tokens = re.split('\\W+', text)\n",
        "    text = [word for word in tokens if word not in stopwords]\n",
        "    return text\n",
        "\n",
        "data['body_text_nostop'] = data['body_text'].apply(lambda x: clean_text(x.lower()))\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl9f1PvgLa_z"
      },
      "source": [
        "### Lemmatize text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmnbBKD7La_z",
        "outputId": "1dff184f-8d14-4b23-9f17-8efa858dba40"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "      <th>body_text_nostop</th>\n",
              "      <th>body_text_lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "      <td>[nah, dont, think, goes, usf, lives, around, though]</td>\n",
              "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
              "      <td>[even, brother, like, speak, treat, like, aids, patent]</td>\n",
              "      <td>[even, brother, like, speak, treat, like, aid, patent]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "      <td>[date, sunday]</td>\n",
              "      <td>[date, sunday]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your call...</td>\n",
              "      <td>[per, request, melle, melle, oru, minnaminunginte, nurungu, vettam, set, callertune, callers, pr...</td>\n",
              "      <td>[per, request, melle, melle, oru, minnaminunginte, nurungu, vettam, set, callertune, caller, pre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spam</td>\n",
              "      <td>WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To c...</td>\n",
              "      <td>[winner, valued, network, customer, selected, receivea, 900, prize, reward, claim, call, 0906170...</td>\n",
              "      <td>[winner, valued, network, customer, selected, receivea, 900, prize, reward, claim, call, 0906170...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>spam</td>\n",
              "      <td>Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with came...</td>\n",
              "      <td>[mobile, 11, months, u, r, entitled, update, latest, colour, mobiles, camera, free, call, mobile...</td>\n",
              "      <td>[mobile, 11, month, u, r, entitled, update, latest, colour, mobile, camera, free, call, mobile, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ham</td>\n",
              "      <td>I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried ...</td>\n",
              "      <td>[im, gonna, home, soon, dont, want, talk, stuff, anymore, tonight, k, ive, cried, enough, today]</td>\n",
              "      <td>[im, gonna, home, soon, dont, want, talk, stuff, anymore, tonight, k, ive, cried, enough, today]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spam</td>\n",
              "      <td>SIX chances to win CASH! From 100 to 20,000 pounds txt&gt; CSH11 and send to 87575. Cost 150p/day, ...</td>\n",
              "      <td>[six, chances, win, cash, 100, 20000, pounds, txt, csh11, send, 87575, cost, 150pday, 6days, 16,...</td>\n",
              "      <td>[six, chance, win, cash, 100, 20000, pound, txt, csh11, send, 87575, cost, 150pday, 6days, 16, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spam</td>\n",
              "      <td>URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM...</td>\n",
              "      <td>[urgent, 1, week, free, membership, 100000, prize, jackpot, txt, word, claim, 81010, tc, wwwdbuk...</td>\n",
              "      <td>[urgent, 1, week, free, membership, 100000, prize, jackpot, txt, word, claim, 81010, tc, wwwdbuk...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  \\\n",
              "0  spam   \n",
              "1   ham   \n",
              "2   ham   \n",
              "3   ham   \n",
              "4   ham   \n",
              "5  spam   \n",
              "6  spam   \n",
              "7   ham   \n",
              "8  spam   \n",
              "9  spam   \n",
              "\n",
              "                                                                                             body_text  \\\n",
              "0  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
              "1                                        Nah I don't think he goes to usf, he lives around here though   \n",
              "2                        Even my brother is not like to speak with me. They treat me like aids patent.   \n",
              "3                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
              "4  As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your call...   \n",
              "5  WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To c...   \n",
              "6  Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with came...   \n",
              "7  I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried ...   \n",
              "8  SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, ...   \n",
              "9  URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM...   \n",
              "\n",
              "                                                                                      body_text_nostop  \\\n",
              "0  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...   \n",
              "1                                                 [nah, dont, think, goes, usf, lives, around, though]   \n",
              "2                                              [even, brother, like, speak, treat, like, aids, patent]   \n",
              "3                                                                                       [date, sunday]   \n",
              "4  [per, request, melle, melle, oru, minnaminunginte, nurungu, vettam, set, callertune, callers, pr...   \n",
              "5  [winner, valued, network, customer, selected, receivea, 900, prize, reward, claim, call, 0906170...   \n",
              "6  [mobile, 11, months, u, r, entitled, update, latest, colour, mobiles, camera, free, call, mobile...   \n",
              "7     [im, gonna, home, soon, dont, want, talk, stuff, anymore, tonight, k, ive, cried, enough, today]   \n",
              "8  [six, chances, win, cash, 100, 20000, pounds, txt, csh11, send, 87575, cost, 150pday, 6days, 16,...   \n",
              "9  [urgent, 1, week, free, membership, 100000, prize, jackpot, txt, word, claim, 81010, tc, wwwdbuk...   \n",
              "\n",
              "                                                                                  body_text_lemmatized  \n",
              "0  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...  \n",
              "1                                                    [nah, dont, think, go, usf, life, around, though]  \n",
              "2                                               [even, brother, like, speak, treat, like, aid, patent]  \n",
              "3                                                                                       [date, sunday]  \n",
              "4  [per, request, melle, melle, oru, minnaminunginte, nurungu, vettam, set, callertune, caller, pre...  \n",
              "5  [winner, valued, network, customer, selected, receivea, 900, prize, reward, claim, call, 0906170...  \n",
              "6  [mobile, 11, month, u, r, entitled, update, latest, colour, mobile, camera, free, call, mobile, ...  \n",
              "7     [im, gonna, home, soon, dont, want, talk, stuff, anymore, tonight, k, ive, cried, enough, today]  \n",
              "8  [six, chance, win, cash, 100, 20000, pound, txt, csh11, send, 87575, cost, 150pday, 6days, 16, t...  \n",
              "9  [urgent, 1, week, free, membership, 100000, prize, jackpot, txt, word, claim, 81010, tc, wwwdbuk...  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def lemmatizing(tokenized_text):\n",
        "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
        "    return text\n",
        "\n",
        "data['body_text_lemmatized'] = data['body_text_nostop'].apply(lambda x: lemmatizing(x))\n",
        "\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important Points:**\n",
        "- Just like the stemmer, the lemmatizer won't do particularly well with slang or abbreviations, so it's not ideal for this data set. It would be impactful to use in case of articles or documents (except if already TF-IDF scores method is used).\n",
        "\n",
        "- Lemmatizer has impacted the following (examples):\n",
        "\n",
        "\n",
        "> 1. lives -> life (line 2 id-1)\n",
        "2. mobiles -> mobile (id-6)\n",
        "\n",
        "The lemmatizer can do some relatively sophisticated things, at least more sophisticated than the stemmer.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M_E26ePx1yIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusions**\n",
        "\n",
        " Both stemming and lemmatizing helps us reduce the corpus of words that the model is exposed to, and it explicitly correlates words with similar meaning.\n",
        "\n",
        " **Trade Off**: The lemmatizer is typically more accurate than the stemmer but the trade-off is that it takes a little bit longer to run.\n",
        " \n",
        " Based on our machine learning pipeline, if the lemmatizer is going to be a bottleneck, then we may opt for the more simple stemmer."
      ],
      "metadata": {
        "id": "u9afW4eC2sdH"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "NLP_Concepts.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}